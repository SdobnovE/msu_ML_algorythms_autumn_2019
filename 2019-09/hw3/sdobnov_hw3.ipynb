{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  3,  3,  3,  4,  4, 25,  1,  2,  3,  4,  5,  3,\n",
       "        3,  3,  4,  4,  5,  1,  1, 21,  1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,3,3,3,4,4,25])\n",
    "b = np.array([1,2,3,4,5,3,3,3,4,4,5,1,1,21,1])\n",
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "\n",
    "np.concatenate((a, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ids = [i for i in range(10)]\n",
    "np.random.shuffle(feature_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        \n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    def __func_gini(self, y_in_v):\n",
    "        N = y_in_v.shape[0]\n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return 1 - (p ** 2).sum()\n",
    "        \n",
    "        \n",
    "    def __gini(self, y_left, y_right):\n",
    "        \n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_gini(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_gini(y_left)\n",
    "                - N_r / N_m * self.__func_gini(y_right))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_entropy(self, y_in_v):\n",
    "        \n",
    "        N = y_in_v.shape[0]\n",
    "        \n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return -(p * np.log2(p)).sum()\n",
    "        \n",
    "    def __entropy(self, y_left, y_right):\n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "\n",
    "        return (self.__func_entropy(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_entropy(y_left)\n",
    "                - N_r / N_m * self.__func_entropy(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_misclass(self, y_in_v):\n",
    "        classes, classes_cnt = np.unique(y_in_v, return_counts=True)\n",
    "        k = classes[classes_cnt.argmax()]\n",
    "        return 1. / y_in_v.shape[0] * (y_in_v == k).sum()\n",
    "    \n",
    "    def __misclass(self, y_left, y_right):\n",
    "        \n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_misclass(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_misclass(y_left)\n",
    "                - N_r / N_m * self.__func_misclass(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        thresholds = x\n",
    "\n",
    "        gains = np.array([self.G_function(y[x <= thr], y[x > thr]) for thr in thresholds])\n",
    "        if gains.min() == 10:\n",
    "            return np.inf, None\n",
    "        ind = gains.argmin()\n",
    "        return gains[ind], (thresholds[ind] + thresholds[ind-1]) / 2. \n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        \n",
    "        if ((self.max_depth is not None and self.max_depth < depth)\n",
    "                or (y.shape[0] < self.min_samples_split)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        threshold = np.array([self.__find_threshold(x[:, feature_id], y)\n",
    "                             for feature_id in feature_ids])\n",
    "        \n",
    "        best_split_id = np.argmin(threshold[:, 0])\n",
    "        gs, best_split = threshold[best_split_id]\n",
    "\n",
    "        if best_split is None:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        x_l, x_r, y_l, y_r = \\\n",
    "            self.__div_samples(x, y, feature_ids[best_split_id], best_split)\n",
    "        if x_l.shape[0] == 0 or x_r.shape[0] == 0:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, feature_ids[best_split_id],\n",
    "                              best_split)\n",
    "\n",
    "        \n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2*node_id + 1, depth + 1, pred_f)\n",
    "        self.__fit_node(x_r, y_r, 2*node_id + 2, depth + 1, pred_f)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion=\"gini\")\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 ms, sys: 41 µs, total: 1.6 ms\n",
      "Wall time: 928 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-653-0eb6edac071d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-653-0eb6edac071d>\u001b[0m in \u001b[0;36m__fit_node\u001b[0;34m(self, x, y, node_id, depth, pred_f)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-653-0eb6edac071d>\u001b[0m in \u001b[0;36m__fit_node\u001b[0;34m(self, x, y, node_id, depth, pred_f)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-653-0eb6edac071d>\u001b[0m in \u001b[0;36m__fit_node\u001b[0;34m(self, x, y, node_id, depth, pred_f)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mfeature_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         threshold = np.array([self.__find_threshold(x[:, feature_id], y)\n\u001b[0;32m--> 140\u001b[0;31m                              for feature_id in feature_ids])\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mbest_split_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-653-0eb6edac071d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mfeature_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         threshold = np.array([self.__find_threshold(x[:, feature_id], y)\n\u001b[0;32m--> 140\u001b[0;31m                              for feature_id in feature_ids])\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mbest_split_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-653-0eb6edac071d>\u001b[0m in \u001b[0;36m__find_threshold\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6484848484848484"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа %time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа %time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        \n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    def __func_gini(self, y_in_v):\n",
    "        N = y_in_v.shape[0]\n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return 1 - (p ** 2).sum()\n",
    "        \n",
    "        \n",
    "    def __gini(self, y_left, y_right):\n",
    "        \n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_gini(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_gini(y_left)\n",
    "                - N_r / N_m * self.__func_gini(y_right))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_entropy(self, y_in_v):\n",
    "        \n",
    "        N = y_in_v.shape[0]\n",
    "        \n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return -(p * np.log2(p)).sum()\n",
    "        \n",
    "    def __entropy(self, y_left, y_right):\n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "\n",
    "        return (self.__func_entropy(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_entropy(y_left)\n",
    "                - N_r / N_m * self.__func_entropy(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_misclass(self, y_in_v):\n",
    "        classes, classes_cnt = np.unique(y_in_v, return_counts=True)\n",
    "        k = classes[classes_cnt.argmax()]\n",
    "        return 1. / y_in_v.shape[0] * (y_in_v == k).sum()\n",
    "    \n",
    "    def __misclass(self, y_left, y_right):\n",
    "        \n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_misclass(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_misclass(y_left)\n",
    "                - N_r / N_m * self.__func_misclass(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        thresholds = x\n",
    "\n",
    "        gains = np.array([self.G_function(y[x <= thr], y[x > thr]) for thr in thresholds])\n",
    "        if gains.min() == 10:\n",
    "            return None\n",
    "        #print(thresholds[gains.argmin()])\n",
    "        print(thresholds)\n",
    "        return thresholds[gains.argmin()]\n",
    "        \n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \n",
    "        if ((y.shape[0] < self.min_samples_split) or\n",
    "            (self.max_depth is not None and self.max_depth < depth)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        main_features = self.get_feature_ids(x.shape[1])\n",
    "        \n",
    "        \n",
    "        thresholds = [self.__find_threshold(x[:,num_feature], y) \n",
    "                               for num_feature in main_features]\n",
    "        \n",
    "        \n",
    "        gains = []\n",
    "        for i in range(len(main_features)):\n",
    "            if thresholds[i] is not None:\n",
    "                gains.append(self.G_function(y[x[:,main_features[i]] <= thresholds[i]], \n",
    "                                 y[x[:,main_features[i]] > thresholds[i]]))\n",
    "            else:\n",
    "                gains.append(10)\n",
    "        \n",
    "        gains = np.array(gains)\n",
    "        \n",
    "        if gains.min() == 10:\n",
    "            \n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "        \n",
    "        index = np.argmin(gains)\n",
    "        \n",
    "        left_indexes = (x[:,index] <= thresholds[index])\n",
    "        right_indexes = (x[:,index] > thresholds[index])\n",
    "        \n",
    "        \n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, main_features[index],\n",
    "                              thresholds[index])\n",
    "        print(y[left_indexes].shape, y[right_indexes].shape)\n",
    "        self.__fit_node(x[left_indexes, :], y[left_indexes], 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(x[right_indexes, :], y[right_indexes], 2 * node_id + 2, depth + 1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
