{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  1,  1,  3,  1,  2,  3,  4,  5,  3,  3,  3,  4,  4,  5,\n",
       "        1,  1, 21,  1])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,1,1,3])\n",
    "b = np.array([1,2,3,4,5,3,3,3,4,4,5,1,1,21,1])\n",
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "\n",
    "np.concatenate((a, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(0.344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ids = [i for i in range(10)]\n",
    "np.random.shuffle(feature_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.16666667, 0.33333333])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(a,return_counts=True)[1] / a.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[2,3,4], [3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -3, -8])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        \n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.depth = 0\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    def __func_gini(self, p):\n",
    "        return 1 - (p ** 2).sum(axis=0)\n",
    "        \n",
    "        \n",
    "    def __gini(self, matr_left, N_l, matr_right, N_r, y_p):\n",
    "        \n",
    "        N_m = N_l + N_r\n",
    "        \n",
    "        return (self.__func_gini(y_p)\n",
    "                - N_l / N_m * self.__func_gini(matr_left)\n",
    "                - N_r / N_m * self.__func_gini(matr_right))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_entropy(self, y_in_v):\n",
    "        \n",
    "        N = y_in_v.shape[0]\n",
    "        \n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return -(p * np.log2(p)).sum()\n",
    "        \n",
    "    def __entropy(self, y_left, y_right):\n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "\n",
    "        return (self.__func_entropy(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_entropy(y_left)\n",
    "                - N_r / N_m * self.__func_entropy(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_misclass(self, y_in_v):\n",
    "        classes, classes_cnt = np.unique(y_in_v, return_counts=True)\n",
    "        k = classes[classes_cnt.argmax()]\n",
    "        return 1. / y_in_v.shape[0] * (y_in_v == k).sum()\n",
    "    \n",
    "    def __misclass(self, y_left, y_right):\n",
    "        \n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_misclass(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_misclass(y_left)\n",
    "                - N_r / N_m * self.__func_misclass(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        ''' информативносьть  + Возвращает порог'''\n",
    "        \n",
    "        x_sort, y_sort = self.__sort_samples(x, y)\n",
    "        all_classes_in_y = np.bincount(y)\n",
    "        ln = all_classes_in_y.shape[0]\n",
    "        matr_right = []\n",
    "        for i in range(1, len(y) - 1):\n",
    "            threshold = x_sort[i]\n",
    "            matr_right.append(np.bincount(y_sort[:i], minlength=ln))\n",
    "        matr_right = np.array(matr_right)\n",
    "        \n",
    "        \n",
    "#         print(np.bincount(y_sort[:1], minlength=ln))    \n",
    "#         print(matr_right.shape,all_classes_in_y.shape)\n",
    "        #print(matr_right.shape, all)\n",
    "        matr_left = all_classes_in_y - matr_right\n",
    "        \n",
    "        matr_left = matr_left.astype(float)\n",
    "        matr_right = matr_right.astype(float)\n",
    "        N_l = np.sum(matr_left)\n",
    "        N_r = np.sum(matr_right)\n",
    "        matr_left /= ln\n",
    "        matr_right /= ln\n",
    "        matr_left = matr_left.T\n",
    "        matr_right = matr_right.T\n",
    "        gains = self.G_function(matr_left, N_l, matr_right, N_r, all_classes_in_y/ln)\n",
    "        #print(gains)\n",
    "        ind = gains.argmin()\n",
    "            \n",
    "        \n",
    "        return gains[ind], (x_sort[ind + 1] + x_sort[ind])/2.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        \n",
    "        self.depth = max(self.depth, depth)\n",
    "        \n",
    "        \n",
    "        if ((self.max_depth is not None and self.max_depth < depth)\n",
    "                or (y.shape[0] < self.min_samples_split)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "        if y.shape[0] == 2:\n",
    "            if y[0] == y[1]:\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, y[0],\n",
    "                                  y[0])\n",
    "                return\n",
    "            else:\n",
    "                self.tree[node_id] = (self.NON_LEAF_TYPE, 0,\n",
    "                              (x[0,0] + x[1,0])/2.)\n",
    "                self.__fit_node(np.array(x[0]), np.array([y[0]]), 2*node_id + 1, depth + 1, pred_f)\n",
    "                self.__fit_node(np.array(x[1]), np.array([y[1]]), 2*node_id + 2, depth + 1, pred_f)\n",
    "                return\n",
    "                \n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        threshold = np.array([self.__find_threshold(x[:, feature_id], y)\n",
    "                             for feature_id in feature_ids])\n",
    "        #print(threshold)\n",
    "        best_split_id = np.argmin(threshold[:, 0])\n",
    "        gs, best_split = threshold[best_split_id]\n",
    "\n",
    "        if best_split is None:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        x_l, x_r, y_l, y_r = \\\n",
    "            self.__div_samples(x, y, feature_ids[best_split_id], best_split)\n",
    "        if x_l.shape[0] == 0 or x_r.shape[0] == 0:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, feature_ids[best_split_id],\n",
    "                              best_split)\n",
    "\n",
    "        \n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2*node_id + 1, depth + 1, pred_f)\n",
    "        self.__fit_node(x_r, y_r, 2*node_id + 2, depth + 1, pred_f)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion=\"gini\")\n",
    "clf = DecisionTreeClassifier(min_samples_split=3, criterion=\"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 ms, sys: 0 ns, total: 1.97 ms\n",
      "Wall time: 1.13 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79.3 ms, sys: 63 µs, total: 79.4 ms\n",
      "Wall time: 78.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3656565656565656"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа %time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа %time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini',\n",
    "                 max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - ((l_c ** 2 / l_s).sum(axis=1)\n",
    "                    + (r_c ** 2 / r_s).sum(axis=1)) / (l_s + r_s)[0]\n",
    "\n",
    "    def __simple_gini(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return y.size * (1 - np.sum((counts / y.size) ** 2))\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return - (((l_c / l_s).log2() * l_c).sum(axis=1)\n",
    "                  + ((r_c / r_s).log2() * r_c).sum(axis=1)) / (l_s + r_s)[0]\n",
    "\n",
    "    def __simple_entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return - y.size * (np.sum((counts / y.size)\n",
    "                                  * np.log2(counts / y.size)))\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - (l_c.max(axis=1) + r_c.max(axis=1)) / (l_s + r_s)[0]\n",
    "\n",
    "    def __simple_misclass(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return y.size * (1 - np.max(counts / y.size))\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода? - сортирует x и y по\n",
    "        # признакам и получает количество классов\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        cut_size = np.int(self.min_samples_split / 2 - 1)\n",
    "\n",
    "        # Что делает этот блок кода? - находит индексы\n",
    "        # в которых происходит смена y, в случае если таких нет\n",
    "        # возвращает None если y не меняется\n",
    "        if cut_size == 0:\n",
    "            splitted_sorted_y = sorted_y\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y[cut_size:-cut_size]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] !=\n",
    "                                splitted_sorted_y[1:])[0] + (cut_size + 1)\n",
    "\n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        # Что делает этот блок кода? - получает количество одинаковых\n",
    "        # элементов в интревале, потом заполняем единицами места где происходит\n",
    "        # смена. Затем делаем матрицу количества классов для каждого интервала\n",
    "        eq_el_count = r_border_ids - np.append(np.array([cut_size]),\n",
    "                                               r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                     sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + \\\n",
    "            np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
    "\n",
    "        # Что делает этот блок кода? - считаем количество классов\n",
    "        # в левой и правой части разбиения\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(sorted_y,\n",
    "                                    minlength=class_number) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода? - считаем неопределенность и\n",
    "        # минимизируем её\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Что делает этот блок кода? - возвращает значение наименьшей\n",
    "        # неопределенности и порога для признака\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE\n",
    "        # self.NON_LEAF_TYPE\n",
    "\n",
    "        # self.tree\n",
    "        # self.max_depth\n",
    "        # self.sufficient_share\n",
    "        # self.min_samples_split\n",
    "\n",
    "        # self.get_feature_ids\n",
    "        # self.__find_threshold\n",
    "        # self.__div_samples\n",
    "        # self.__fit_node\n",
    "        if ((self.max_depth is not None and self.max_depth < depth)\n",
    "                or (y.shape[0] < self.min_samples_split)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        threshold = np.array([self.__find_threshold(x[:, feature_id], y)\n",
    "                             for feature_id in feature_ids])\n",
    "        best_split_id = np.argmin(threshold[:, 0])\n",
    "        gs, best_split = threshold[best_split_id]\n",
    "\n",
    "        if best_split is None:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        x_l, x_r, y_l, y_r = \\\n",
    "            self.__div_samples(x, y, feature_ids[best_split_id], best_split)\n",
    "        if x_l.shape[0] == 0 or x_r.shape[0] == 0:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, feature_ids[best_split_id],\n",
    "                              best_split)\n",
    "\n",
    "        if self.G_function == self.__gini:\n",
    "            gain_fun = self.__simple_gini\n",
    "        elif self.G_function == self.__entropy:\n",
    "            gain_fun = self.__simple_entropy\n",
    "        elif self.G_function == self.__misclass:\n",
    "            gain_fun = self.__simple_misclass\n",
    "\n",
    "        self.feature_importances_[best_split_id] += \\\n",
    "            gain_fun(y) - gain_fun(y_l) - gain_fun(y_r)\n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2*node_id + 1, depth + 1, pred_f)\n",
    "        self.__fit_node(x_r, y_r, 2*node_id + 2, depth + 1, pred_f)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        \n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.depth = 0\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    def __func_gini(self, y_in_v):\n",
    "        N = y_in_v.shape[0]\n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return 1 - (p ** 2).sum()\n",
    "        \n",
    "        \n",
    "    def __gini(self, y_left, y_right):\n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_gini(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_gini(y_left)\n",
    "                - N_r / N_m * self.__func_gini(y_right))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_entropy(self, y_in_v):\n",
    "        \n",
    "        N = y_in_v.shape[0]\n",
    "        \n",
    "        p = np.unique(y_in_v, return_counts=True)[1] / N\n",
    "        return -(p * np.log2(p)).sum()\n",
    "        \n",
    "    def __entropy(self, y_left, y_right):\n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "\n",
    "        return (self.__func_entropy(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_entropy(y_left)\n",
    "                - N_r / N_m * self.__func_entropy(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __func_misclass(self, y_in_v):\n",
    "        classes, classes_cnt = np.unique(y_in_v, return_counts=True)\n",
    "        k = classes[classes_cnt.argmax()]\n",
    "        return 1. / y_in_v.shape[0] * (y_in_v == k).sum()\n",
    "    \n",
    "    def __misclass(self, y_left, y_right):\n",
    "        \n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0: \n",
    "            return 10\n",
    "        y_left = y_left.astype('float')\n",
    "        y_right = y_right.astype('float')\n",
    "        N_l = y_left.shape[0]\n",
    "        N_r  = y_right.shape[0]\n",
    "        N_m = N_l + N_r\n",
    "        return (self.__func_misclass(np.concatenate((y_left, y_right), axis=0))\n",
    "                - N_l / N_m * self.__func_misclass(y_left)\n",
    "                - N_r / N_m * self.__func_misclass(y_right))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        x_sort,y_sort = self.__sort_samples(x, y)\n",
    "        ln =  x.shape[0]\n",
    "        step = (x.max() - x.min()) / ln\n",
    "        \n",
    "        if y.shape[0] == 2:\n",
    "            gains = np.array([self.G_function(y_sort[x_sort <= x_sort[0] + 1e-16], y_sort[x_sort > x_sort[0] + 1e-16])])\n",
    "        else:\n",
    "            gains = np.array([self.G_function(y_sort[x_sort <= x_sort[i] + 1e-16], y_sort[x_sort > x_sort[i] + 1e-16])\n",
    "                              for i in range(0, ln - 1)])\n",
    "        \n",
    "        if gains.min() == 10:\n",
    "            return np.inf, None\n",
    "        \n",
    "        ind = gains.argmin()\n",
    "        \n",
    "        return gains[ind], (x_sort[ind])\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        #print(x.shape)\n",
    "        self.depth = max(self.depth, depth)\n",
    "        if ((self.max_depth is not None and self.max_depth < depth)\n",
    "                or (y.shape[0] < self.min_samples_split)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        threshold = np.array([self.__find_threshold(x[:, feature_id], y)\n",
    "                             for feature_id in feature_ids])\n",
    "        \n",
    "        best_split_id = np.argmin(threshold[:, 0])\n",
    "        gs, best_split = threshold[best_split_id]\n",
    "\n",
    "        if best_split is None:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        x_l, x_r, y_l, y_r = \\\n",
    "            self.__div_samples(x, y, feature_ids[best_split_id], best_split)\n",
    "        if x_l.shape[0] == 0 or x_r.shape[0] == 0:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, feature_ids[best_split_id],\n",
    "                              best_split)\n",
    "\n",
    "        \n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2*node_id + 1, depth + 1, pred_f)\n",
    "        self.__fit_node(x_r, y_r, 2*node_id + 2, depth + 1, pred_f)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
